"2019-08-24 16:32:40,899 - hetero_ne_host.py[line:47] - INFO: Enter hetero_ne host"
"2019-08-24 16:32:40,899 - hetero_ne_host.py[line:49] - INFO: Host party has 30 nodes"
"2019-08-24 16:32:40,929 - hetero_ne_host.py[line:52] - INFO: Transform input data to train instance"
"2019-08-24 16:32:40,930 - hetero_ne_host.py[line:59] - INFO: Get Publick key from arbiter:<PaillierPublicKey 1a27ce815c>"
"2019-08-24 16:32:40,930 - hetero_ne_host.py[line:64] - INFO: Generate mini-batch for local instances in guest"
"2019-08-24 16:32:42,413 - hetero_ne_host.py[line:72] - INFO: Get batch_info from guest: {'batch_size': 1024, 'batch_num': 1}"
"2019-08-24 16:32:42,413 - hetero_ne_host.py[line:86] - INFO: Start initilize model."
"2019-08-24 16:32:42,414 - hetero_ne_host.py[line:93] - INFO: iter: 0"
"2019-08-24 16:32:42,414 - hetero_ne_host.py[line:99] - INFO: Horizontally learning"
"2019-08-24 16:32:42,415 - hetero_ne_host.py[line:102] - INFO: Local batch data count:306"
"2019-08-24 16:32:47,705 - hetero_ne_host.py[line:115] - INFO: gradient count:306"
"2019-08-24 16:32:48,232 - hetero_ne_host.py[line:139] - INFO: Iter 0, Local loss: 1.408838791638017"
"2019-08-24 16:32:48,232 - hetero_ne_host.py[line:146] - INFO: batch:0"
"2019-08-24 16:32:48,334 - hetero_ne_host.py[line:159] - INFO: Get batch_index from Guest"
"2019-08-24 16:32:48,381 - hetero_ne_host.py[line:172] - INFO: batch_data_inst size:42"
"2019-08-24 16:32:49,926 - hetero_ne_host.py[line:187] - INFO: Remote host_forward to guest"
"2019-08-24 16:32:51,634 - hetero_ne_host.py[line:197] - INFO: Get optim_host_gradient from arbiter"
"2019-08-24 16:32:51,694 - hetero_ne_host.py[line:200] - INFO: update_model"
"2019-08-24 16:32:52,575 - hetero_ne_host.py[line:242] - INFO: Get is_stop flag from arbiter:False"
"2019-08-24 16:32:52,575 - hetero_ne_host.py[line:93] - INFO: iter: 1"
"2019-08-24 16:32:52,575 - hetero_ne_host.py[line:99] - INFO: Horizontally learning"
"2019-08-24 16:32:52,578 - hetero_ne_host.py[line:102] - INFO: Local batch data count:306"
"2019-08-24 16:32:57,601 - hetero_ne_host.py[line:115] - INFO: gradient count:306"
"2019-08-24 16:33:00,016 - hetero_ne_host.py[line:139] - INFO: Iter 1, Local loss: 1.3412028646529903"
"2019-08-24 16:33:00,016 - hetero_ne_host.py[line:146] - INFO: batch:0"
"2019-08-24 16:33:00,016 - hetero_ne_host.py[line:172] - INFO: batch_data_inst size:42"
"2019-08-24 16:33:03,635 - hetero_ne_host.py[line:187] - INFO: Remote host_forward to guest"
"2019-08-24 16:33:05,444 - hetero_ne_host.py[line:197] - INFO: Get optim_host_gradient from arbiter"
"2019-08-24 16:33:05,578 - hetero_ne_host.py[line:200] - INFO: update_model"
"2019-08-24 16:33:06,781 - hetero_ne_host.py[line:242] - INFO: Get is_stop flag from arbiter:False"
"2019-08-24 16:33:06,781 - hetero_ne_host.py[line:93] - INFO: iter: 2"
"2019-08-24 16:33:06,781 - hetero_ne_host.py[line:99] - INFO: Horizontally learning"
"2019-08-24 16:33:06,786 - hetero_ne_host.py[line:102] - INFO: Local batch data count:306"
"2019-08-24 16:33:11,654 - hetero_ne_host.py[line:115] - INFO: gradient count:306"
"2019-08-24 16:33:12,253 - hetero_ne_host.py[line:139] - INFO: Iter 2, Local loss: 1.3220067772862316"
"2019-08-24 16:33:12,253 - hetero_ne_host.py[line:146] - INFO: batch:0"
"2019-08-24 16:33:12,254 - hetero_ne_host.py[line:172] - INFO: batch_data_inst size:42"
"2019-08-24 16:33:13,859 - hetero_ne_host.py[line:187] - INFO: Remote host_forward to guest"
"2019-08-24 16:33:15,467 - hetero_ne_host.py[line:197] - INFO: Get optim_host_gradient from arbiter"
"2019-08-24 16:33:15,522 - hetero_ne_host.py[line:200] - INFO: update_model"
"2019-08-24 16:33:16,531 - hetero_ne_host.py[line:242] - INFO: Get is_stop flag from arbiter:False"
"2019-08-24 16:33:16,531 - hetero_ne_host.py[line:93] - INFO: iter: 3"
"2019-08-24 16:33:16,531 - hetero_ne_host.py[line:99] - INFO: Horizontally learning"
"2019-08-24 16:33:16,535 - hetero_ne_host.py[line:102] - INFO: Local batch data count:306"
"2019-08-24 16:33:25,107 - hetero_ne_host.py[line:115] - INFO: gradient count:306"
"2019-08-24 16:33:25,556 - hetero_ne_host.py[line:139] - INFO: Iter 3, Local loss: 1.3050741986155099"
"2019-08-24 16:33:25,556 - hetero_ne_host.py[line:146] - INFO: batch:0"
"2019-08-24 16:33:25,556 - hetero_ne_host.py[line:172] - INFO: batch_data_inst size:42"
"2019-08-24 16:33:27,126 - hetero_ne_host.py[line:187] - INFO: Remote host_forward to guest"
"2019-08-24 16:33:28,834 - hetero_ne_host.py[line:197] - INFO: Get optim_host_gradient from arbiter"
"2019-08-24 16:33:28,922 - hetero_ne_host.py[line:200] - INFO: update_model"
"2019-08-24 16:33:29,973 - hetero_ne_host.py[line:242] - INFO: Get is_stop flag from arbiter:False"
"2019-08-24 16:33:29,974 - hetero_ne_host.py[line:93] - INFO: iter: 4"
"2019-08-24 16:33:29,974 - hetero_ne_host.py[line:99] - INFO: Horizontally learning"
"2019-08-24 16:33:29,980 - hetero_ne_host.py[line:102] - INFO: Local batch data count:306"
"2019-08-24 16:33:36,153 - hetero_ne_host.py[line:115] - INFO: gradient count:306"
"2019-08-24 16:33:36,393 - hetero_ne_host.py[line:139] - INFO: Iter 4, Local loss: 1.2900791202058162"
"2019-08-24 16:33:36,393 - hetero_ne_host.py[line:146] - INFO: batch:0"
"2019-08-24 16:33:36,394 - hetero_ne_host.py[line:172] - INFO: batch_data_inst size:42"
"2019-08-24 16:33:38,330 - hetero_ne_host.py[line:187] - INFO: Remote host_forward to guest"
"2019-08-24 16:33:39,737 - hetero_ne_host.py[line:197] - INFO: Get optim_host_gradient from arbiter"
"2019-08-24 16:33:39,802 - hetero_ne_host.py[line:200] - INFO: update_model"
"2019-08-24 16:33:40,737 - hetero_ne_host.py[line:242] - INFO: Get is_stop flag from arbiter:False"
"2019-08-24 16:33:40,737 - hetero_ne_host.py[line:248] - INFO: Reach max iter 5, train mode finish!"
"2019-08-24 16:33:42,958 - hetero_ne_host.py[line:254] - INFO: Reach max iter 5, train model finish!"
